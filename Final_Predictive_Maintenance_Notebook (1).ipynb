{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584a1c4e-d1d9-4d7d-8e69-72d456eb72ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.5' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '\"c:/Program Files/Python313/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('balanced_simulated_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================\n",
    "# STEP 2: Exploratory Data Analysis (EDA)\n",
    "# ===============================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Basic Information\n",
    "print(\"### Data Info ###\")\n",
    "print(data.info())\n",
    "print(\"\\n### Data Description ###\")\n",
    "print(data.describe())\n",
    "\n",
    "# 2. Class Balance for Maintenance\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.countplot(x='maintenance', data=data, palette='viridis')\n",
    "plt.title(\"Maintenance Class Distribution (0 = Normal, 1 = Needs Maintenance)\")\n",
    "plt.xlabel(\"Maintenance Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Distribution of Sensor Readings\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "sns.histplot(data['sensor_temp'], bins=30, kde=True, ax=axs[0])\n",
    "axs[0].set_title('Sensor Temperature Distribution')\n",
    "\n",
    "sns.histplot(data['sensor_vib'], bins=30, kde=True, ax=axs[1])\n",
    "axs[1].set_title('Sensor Vibration Distribution')\n",
    "\n",
    "sns.histplot(data['sensor_voltage'], bins=30, kde=True, ax=axs[2])\n",
    "axs[2].set_title('Sensor Voltage Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Correlation Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(data.corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# 5. RUL vs Operational Hours\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x='operational_hours', y='RUL', hue='maintenance', data=data, palette='coolwarm')\n",
    "plt.title(\"RUL vs Operational Hours (Colored by Maintenance)\")\n",
    "plt.xlabel(\"Operational Hours\")\n",
    "plt.ylabel(\"Remaining Useful Life (RUL)\")\n",
    "plt.legend(title=\"Maintenance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================\n",
    "# STEP 3: Classification\n",
    "# ===============================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define features and target\n",
    "features = ['sensor_temp', 'sensor_vib', 'sensor_voltage', 'operational_hours']\n",
    "target_clf = 'maintenance'\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[features], data[target_clf], test_size=0.2, random_state=42, stratify=data[target_clf]\n",
    ")\n",
    "\n",
    "# Train classifier\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3308583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================\n",
    "# STEP 4: Regression for RUL\n",
    "# ===============================\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Target for regression\n",
    "target_reg = 'RUL'\n",
    "\n",
    "# Train-test split for regression\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    data[features], data[target_reg], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train regression model\n",
    "reg = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_reg = reg.predict(X_test_reg)\n",
    "\n",
    "# Evaluate performance\n",
    "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(f\"Root Mean Squared Error (hours): {rmse:.2f}\")\n",
    "print(f\"RÂ² Score: {r2:.2f}\")\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_reg, y_pred_reg, alpha=0.6, color='green')\n",
    "plt.plot([0, max(y_test_reg)], [0, max(y_test_reg)], 'r--')\n",
    "plt.xlabel(\"Actual RUL (hours)\")\n",
    "plt.ylabel(\"Predicted RUL (hours)\")\n",
    "plt.title(\"Actual vs Predicted RUL\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance\n",
    "importances = reg.feature_importances_\n",
    "feature_names = X_train_reg.columns\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.barh(feature_names, importances, color='teal')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance for RUL Prediction\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================\n",
    "# STEP 5: Clustering for Anomaly Detection\n",
    "# ===============================\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Fit KMeans (2 clusters: normal vs anomaly)\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(data[features])\n",
    "\n",
    "# Add cluster labels to your DataFrame\n",
    "data['cluster'] = kmeans.labels_\n",
    "\n",
    "# Step: Identify which cluster is more degraded (i.e., lower RUL)\n",
    "cluster_rul_mean = data.groupby('cluster')['RUL'].mean()\n",
    "anomaly_cluster = cluster_rul_mean.idxmin()  # Lower RUL = more likely degraded/anomaly\n",
    "\n",
    "# Step: Create human-readable labels\n",
    "data['anomaly_label'] = data['cluster'].apply(\n",
    "    lambda x: 'Anomaly' if x == anomaly_cluster else 'Normal'\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(data=data, x='sensor_temp', y='sensor_vib', hue='cluster', palette='Set1')\n",
    "plt.title('Sensor Clustering (KMeans)')\n",
    "plt.xlabel('Sensor Temperature')\n",
    "plt.ylabel('Sensor Vibration')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# RUL distribution by anomaly label\n",
    "sns.boxplot(x='anomaly_label', y='RUL', data=data)\n",
    "plt.title(\"RUL Distribution by Anomaly Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9681b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Calculate distances to cluster centers\n",
    "distances = cdist(data[features], kmeans.cluster_centers_)\n",
    "\n",
    "# Minimum distance to assigned cluster\n",
    "data['distance_to_center'] = [distances[i, label] for i, label in enumerate(data['cluster'])]\n",
    "\n",
    "# Define thresholds\n",
    "rul_threshold = 200  # hours\n",
    "distance_threshold = data['distance_to_center'].quantile(0.90)  # top 10% farthest points\n",
    "\n",
    "# Hybrid anomaly detection\n",
    "data['anomaly_label'] = data.apply(\n",
    "    lambda row: 'Anomaly' if (row['RUL'] < rul_threshold or row['distance_to_center'] > distance_threshold) else 'Normal',\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fbc253-fb06-4930-ba2c-56878b8db04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unified Prediction Code for Multiple Samples\n",
    "\n",
    "def predict_maintenance(features):\n",
    "    # Convert input to DataFrame\n",
    "    features_df = pd.DataFrame([features], columns=['sensor_temp', 'sensor_vib', 'sensor_voltage', 'operational_hours'])\n",
    "    \n",
    "    # Scale input\n",
    "    features_scaled = scaler.transform(features_df)\n",
    "    \n",
    "    # Predictions\n",
    "    rul_pred = reg.predict(features_scaled)\n",
    "    maint_pred = clf.predict(features_scaled)\n",
    "    \n",
    "    # Cluster and distance\n",
    "    cluster_pred = kmeans.predict(features_scaled)\n",
    "    distance = cdist(features_scaled, kmeans.cluster_centers_)[0, cluster_pred[0]]\n",
    "    \n",
    "    # Hybrid anomaly detection\n",
    "    anomaly = 'Anomaly' if (rul_pred[0] < 200 or distance > distance_threshold) else 'Normal'\n",
    "\n",
    "    return {\n",
    "        'RUL Prediction (hours)': round(rul_pred[0], 2),\n",
    "        'Maintenance Prediction': 'Needs Maintenance' if maint_pred[0] == 1 else 'Normal',\n",
    "        'Anomaly Detection': anomaly\n",
    "    }\n",
    "\n",
    "# ---------------- SAMPLE PREDICTIONS ----------------\n",
    "sample_features_healthy = [30, 0.4, 220, 500]\n",
    "prediction_healthy = predict_maintenance(sample_features_healthy)\n",
    "\n",
    "sample_features_failing = [90, 1.0, 210, 2900]\n",
    "prediction_failing = predict_maintenance(sample_features_failing)\n",
    "\n",
    "print(\"Sample Features (Healthy):\", sample_features_healthy)\n",
    "print(\"Prediction (Healthy):\", prediction_healthy)\n",
    "print(\"\\nSample Features (Failing):\", sample_features_failing)\n",
    "print(\"Prediction (Failing):\", prediction_failing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6afff-ce35-42a1-93d1-8ceb9a0bcb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6345a2bc-ec4c-4537-adc0-ac9b534a7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save models and scaler\n",
    "with open('reg_model.pkl', 'wb') as f:\n",
    "    pickle.dump(reg, f)\n",
    "\n",
    "with open('clf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "with open('kmeans_model.pkl', 'wb') as f:\n",
    "    pickle.dump(kmeans, f)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"All models and scaler have been saved as .pkl files!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
